{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d0edab-ed20-4bb8-b087-b0ace473dcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capstone Project by Archana Adhi, Havanitha Macha and Shravan Busireddy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560d709e-fef8-4816-a715-ffded2fe051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ARES(n_docs, query, key ,k ,claude_key,deepseek_key ):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "        ARES - Automatic Response Evaluation System\n",
    "\n",
    "             Evaluates the LLM  generated response for a medical query on these metrics.\n",
    "                     \n",
    "        Args:\n",
    "             n_docs(int) : Number of documents to retrieve from Pubmed and Europe PMC.\n",
    "             query (str): User Medical query to evaluate.\n",
    "             key (str): API key for OpenAI GPT models.\n",
    "             k (int): Number of  top documents to retrieve with calculated scores.\n",
    "             claude_key (str): API key for Claude models.\n",
    "             deepseek_key (str): API key for DeepSeek models.\n",
    "        \n",
    "        Returns:       \n",
    "             pubmed_query (str): Reformulated  query generated by LLM which is used for PubMed retrieval.\n",
    "             pseudo_gold (str): Pseudo-ground truth document synthesized by LLM from top-k retrieved documents.\n",
    "             df (pd.DataFrame): DataFrame containing BM25 and dense scores.\n",
    "             chatgpt_RE (str): Evaluation result of ChatGPT response.\n",
    "             claude_RE (str): Evaluation result of Claude response.\n",
    "             deepseek_RE (str): Evaluation result of Deepseek response.\n",
    "             empathy_evaluation (str): Empathy scores for each model's response.\n",
    "             chatgpt_response (str): Response generated by ChatGPT for user query.\n",
    "             claude_response (str): Response generated by Claude for user query.\n",
    "             deepseek_response (str): Response generated by Claude for user query. \n",
    "\n",
    "    \"\"\"\n",
    "    #import dependencies and ignore warnings\n",
    "    \n",
    "    import openai\n",
    "    from openai import OpenAI\n",
    "    import re\n",
    "    from typing import Optional\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import pandas as pd\n",
    "    from langchain.embeddings import OpenAIEmbeddings\n",
    "    from langchain.vectorstores import FAISS\n",
    "    from langchain.schema import Document\n",
    "    from rank_bm25 import BM25Okapi\n",
    "    import numpy as np\n",
    "    import openai\n",
    "    from typing import List, Optional\n",
    "    import openai\n",
    "    from typing import List, Dict\n",
    "    from anthropic import Anthropic\n",
    "    from typing import Optional\n",
    "    import json \n",
    "    import warnings\n",
    "    from Bio import Entrez\n",
    "    from xml.etree import ElementTree as ET\n",
    "    \n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "    \n",
    "    def get_medical_advice_deepseek(patient_query: str, api_key: str, model: str = 'deepseek-chat') -> Optional[str]:\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        Get medical advice from DeepSeek v3 in the style of a doctor's response.\n",
    "    \n",
    "        Args:\n",
    "            patient_query: The patient's description of their condition.\n",
    "            api_key: DeepSeek API key.\n",
    "            model: DeepSeek model to use (default: \"deepseek-chat\").\n",
    "    \n",
    "        Returns:\n",
    "            The generated medical advice, or None if generation failed.\n",
    "        \"\"\"\n",
    "        if not patient_query or not isinstance(patient_query, str):\n",
    "            raise ValueError(\"Patient query must be a non-empty string\")\n",
    "        if not api_key or not isinstance(api_key, str):\n",
    "            raise ValueError(\"API key must be a non-empty string\")\n",
    "    \n",
    "        try:\n",
    "            url = \"https://api.deepseek.com/v1/chat/completions\"  # Confirm this endpoint from DeepSeek docs\n",
    "            headers = {\n",
    "                \"Authorization\": f\"Bearer {api_key}\",\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            }\n",
    "    \n",
    "            system_message = (\n",
    "                \"You are a highly knowledgeable and compassionate doctor.\\n\"\n",
    "                \"1. Carefully analyze the patient's symptoms and concerns.\\n\"\n",
    "                \"2. Suggest possible causes, but never give a definitive diagnosis.\\n\"\n",
    "                \"3. Offer evidence-based advice for relief and care.\\n\"\n",
    "                \"4. Always recommend in-person consultation with a healthcare provider.\\n\"\n",
    "                \"5. Be clear, empathetic, and professional in tone.\\n\"\n",
    "                \"6. Consider lifestyle and other details mentioned by the patient.\\n\"\n",
    "                \"7. Avoid exaggeration or alarming language.\"\n",
    "            )\n",
    "    \n",
    "            payload = {\n",
    "                \"model\": model,\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": system_message},\n",
    "                    {\"role\": \"user\", \"content\": patient_query}\n",
    "                ],\n",
    "                \"temperature\": 0.2,\n",
    "                \"max_tokens\": 800\n",
    "            }\n",
    "    \n",
    "            response = requests.post(url, headers=headers, json=payload)\n",
    "    \n",
    "            if response.status_code == 200:\n",
    "                return response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            else:\n",
    "                print(\"DeepSeek API error:\", response.status_code, response.text)\n",
    "                return None\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating medical advice with DeepSeek: {e}\")\n",
    "            return None\n",
    "    deepseek_response = get_medical_advice_deepseek(query, api_key=deepseek_key)\n",
    "\n",
    "    \n",
    "    def get_medical_advice_claude(patient_query: str, api_key: str, model: str = \"claude-3-opus-20240229\") -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Get medical advice from Claude in the style of a doctor's response.\n",
    "    \n",
    "        Args:\n",
    "            patient_query: The patient's description of their condition.\n",
    "            api_key: Anthropic API key.\n",
    "            model: Claude model to use (defaults to \"claude-3-opus-20240229\").\n",
    "    \n",
    "        Returns:\n",
    "            The generated medical advice, or None if generation failed.\n",
    "        \"\"\"\n",
    "        if not patient_query or not isinstance(patient_query, str):\n",
    "            raise ValueError(\"Patient query must be a non-empty string\")\n",
    "        if not api_key or not isinstance(api_key, str):\n",
    "            raise ValueError(\"API key must be a non-empty string\")\n",
    "    \n",
    "        try:\n",
    "            client = Anthropic(api_key=api_key)\n",
    "    \n",
    "            system_message = \"\"\"You are a highly knowledgeable and compassionate doctor.\n",
    "    1. Carefully analyze the patient's symptoms and concerns.\n",
    "    2. Suggest possible causes, but never give a definitive diagnosis.\n",
    "    3. Offer evidence-based advice for relief and care.\n",
    "    4. Always recommend in-person consultation with a healthcare provider.\n",
    "    5. Be clear, empathetic, and professional in tone.\n",
    "    6. Consider lifestyle and other details mentioned by the patient.\n",
    "    7. Avoid exaggeration or alarming language.\"\"\"\n",
    "    \n",
    "            response = client.messages.create(\n",
    "                model=model,\n",
    "                system=system_message,\n",
    "                max_tokens=800,\n",
    "                temperature=0.2,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": patient_query}\n",
    "                ]\n",
    "            )\n",
    "    \n",
    "            return response.content[0].text\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating medical advice with Claude: {e}\")\n",
    "            return None\n",
    "\n",
    "    claude_response = get_medical_advice_claude(query, api_key=claude_key)        \n",
    "\n",
    "\n",
    "    def get_medical_advice(patient_query: str, api_key: str, model: str = \"gpt-4-turbo\") -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Get medical advice from GPT-4-turbo/4o in the style of a doctor's response.\n",
    "        \n",
    "        Args:\n",
    "            patient_query: The patient's description of their condition\n",
    "            api_key: OpenAI API key\n",
    "            model: Which OpenAI model to use (defaults to \"gpt-4-turbo\")\n",
    "        \n",
    "        Returns:\n",
    "            The generated medical advice, or None if generation failed\n",
    "        \"\"\"\n",
    "        # Validate inputs\n",
    "        if not patient_query or not isinstance(patient_query, str):\n",
    "            raise ValueError(\"Patient query must be a non-empty string\")\n",
    "        if not api_key or not isinstance(api_key, str):\n",
    "            raise ValueError(\"API key must be a non-empty string\")\n",
    "    \n",
    "        try:\n",
    "            # Initialize client\n",
    "            client = openai.OpenAI(api_key=api_key)\n",
    "            \n",
    "            # Create the system message to guide the AI's response\n",
    "            system_message = \"\"\"You are a very knowledgeable and compassionate doctor. \n",
    "            When responding to medical questions:\n",
    "            1. Carefully analyze the patient's description\n",
    "            2. Provide possible causes based on the symptoms described\n",
    "            3. Offer practical, evidence-based suggestions for relief\n",
    "            4. Always recommend consulting an in-person doctor for proper diagnosis\n",
    "            5. Maintain a professional yet empathetic tone\n",
    "            6. Never claim to definitively diagnose - only suggest possibilities\n",
    "            7. Consider the patient's lifestyle factors mentioned\"\"\"\n",
    "            \n",
    "            # Call OpenAI API\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_message},\n",
    "                    {\"role\": \"user\", \"content\": patient_query}\n",
    "                ],\n",
    "                temperature=0.2,  # Slightly lower for more focused medical advice\n",
    "                max_tokens=800\n",
    "            )\n",
    "    \n",
    "            return response.choices[0].message.content\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating medical advice: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    \n",
    "    \n",
    "        # Get the medical advice\n",
    "    chatgpt_response = get_medical_advice(query, api_key=key)\n",
    "\n",
    "\n",
    "    llmresponse = chatgpt_response + claude_response + deepseek_response\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    client = OpenAI(api_key=key)  # Replace with your actual API key\n",
    "    \n",
    "    def generate_pubmed_query(natural_query: str) -> str:\n",
    "        \"\"\"\n",
    "        Generates high-recall PubMed queries wrapped in triple quotes for immediate use.\n",
    "        Returns queries in this format:\n",
    "        '''\n",
    "        (term1 OR term2) AND (term3 OR term4)\n",
    "        '''\n",
    "        \"\"\"\n",
    "        system_prompt = \"\"\"You are a PubMed search expert that creates queries with:\n",
    "        1. HIGH RECALL: Prioritize finding all relevant papers\n",
    "        2. READY-TO-USE: Format with triple quotes (''') at start and end\n",
    "        3. TERM EXPANSION: Include 3-5 synonyms per concept\n",
    "        4. STRUCTURE: Follow this exact template:\n",
    "        '''\n",
    "        (concept1 OR synonym OR synonym) \n",
    "        AND \n",
    "        (concept2 OR synonym OR synonym)\n",
    "        [AND (optional filter)]\n",
    "        '''\n",
    "        \n",
    "        Output MUST include the triple quotes and be copy-paste ready.\"\"\"\n",
    "        \n",
    "        user_prompt = f\"\"\"Convert this to a ready-to-use PubMed query with triple quotes:\n",
    "        \n",
    "        WORKING EXAMPLE:\n",
    "        Input: \"effects of prolonged computer use on back pain\"\n",
    "        Output: '''\n",
    "        (\"back pain\" OR \"low back pain\") \n",
    "        AND \n",
    "        (\"computer use\" OR \"prolonged sitting\")\n",
    "        AND \n",
    "        (\"chronic pain\" OR \"musculoskeletal pain\")\n",
    "        '''\n",
    "        \n",
    "        Now convert this:\n",
    "        {natural_query}\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                temperature=0.1,\n",
    "                max_tokens=150\n",
    "            )\n",
    "            \n",
    "            # Extract and validate the query\n",
    "            raw_query = response.choices[0].message.content\n",
    "            clean_query = raw_query.strip()\n",
    "            \n",
    "            # Verify triple quotes are present\n",
    "            if not clean_query.startswith(\"'''\") or not clean_query.endswith(\"'''\"):\n",
    "                clean_query = f\"'''\\n{clean_query}\\n'''\"\n",
    "                \n",
    "            return clean_query\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating query: {e}\")\n",
    "            # Fallback with triple quotes\n",
    "            terms = re.findall(r'\\b[\\w-]+\\b', natural_query.lower())[:3]\n",
    "            base_query = f'\"{terms[0]}\" AND \"{terms[1]}\"' if len(terms) > 1 else f'\"{terms[0]}\"'\n",
    "            return f\"'''\\n{base_query}\\n'''\"\n",
    "    \n",
    "    pubmed_query = generate_pubmed_query(query)\n",
    "    #pubmed query is generated\n",
    "    \n",
    "\n",
    "    Entrez.email = \"YOUR_EMAIL\"  # Replace with your actual email\n",
    "    \n",
    "    def fetch_pubmed_docs_with_dates(query, retmax):\n",
    "\n",
    "        \n",
    "       \"\"\"\n",
    "        Fetch PubMed articles for a given search query and return their PMIDs, titles, abstracts, and publication years.\n",
    "    \n",
    "        Args:\n",
    "            query (str): The search term or query to use in PubMed.\n",
    "            retmax (int): The maximum number of articles to retrieve.\n",
    "    \n",
    "        Returns:\n",
    "            List[Dict[str, str]]: A list of dictionaries, each containing:\n",
    "                - 'pmid': PubMed ID of the article.\n",
    "                - 'title': Title of the article.\n",
    "                - 'abstract': Abstract text (concatenated if multiple sections).\n",
    "                - 'year': Publication year (extracted from PubDate, or 'Unknown' if not found).\n",
    "        \"\"\"\n",
    "        \n",
    "        # Step 1: Search for PubMed IDs\n",
    "        search_handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=retmax)\n",
    "        search_results = Entrez.read(search_handle)\n",
    "        search_handle.close()\n",
    "    \n",
    "        id_list = search_results[\"IdList\"]\n",
    "        \n",
    "        # Step 2: Fetch article data\n",
    "        fetch_handle = Entrez.efetch(db=\"pubmed\", id=\",\".join(id_list), rettype=\"abstract\", retmode=\"xml\")\n",
    "        xml_data = fetch_handle.read()\n",
    "        fetch_handle.close()\n",
    "    \n",
    "        root = ET.fromstring(xml_data)\n",
    "        results = []\n",
    "    \n",
    "        for article in root.findall(\".//PubmedArticle\"):\n",
    "            pmid = article.findtext(\".//PMID\", default=\"\").strip()\n",
    "            title = article.findtext(\".//ArticleTitle\", default=\"\").strip()\n",
    "    \n",
    "            abstract_texts = article.findall(\".//Abstract/AbstractText\")\n",
    "            abstract = \" \".join(elem.text.strip() for elem in abstract_texts if elem.text)\n",
    "            full_doc = f\"{title}. {abstract}\" if abstract else title\n",
    "    \n",
    "            # Extract publication date\n",
    "            date_elem = article.find(\".//PubDate\")\n",
    "            if date_elem is not None:\n",
    "                year = date_elem.findtext(\"Year\") or \"\"\n",
    "                month = date_elem.findtext(\"Month\") or \"\"\n",
    "                day = date_elem.findtext(\"Day\") or \"\"\n",
    "                pub_date = f\"{year}-{month}-{day}\".strip(\"-\")\n",
    "            else:\n",
    "                pub_date = \"Unknown\"\n",
    "    \n",
    "            results.append({\n",
    "                \"pmid\": pmid,\n",
    "                \"title\": title,\n",
    "                \"abstract\": abstract,\n",
    "                \"year\": pub_date[:4]\n",
    "            })\n",
    "    \n",
    "        return results\n",
    "    \n",
    "    \n",
    "    pub_docs=fetch_pubmed_docs_with_dates(pubmed_query, retmax=n_docs)\n",
    "    print(len(pub_docs))\n",
    "\n",
    "\n",
    "\n",
    "    def fetch_pubmed_articles(pubmed_query, page_size=None):\n",
    "        \"\"\"\n",
    "        Fetches PubMed articles based on a search query and extracts relevant information.\n",
    "        \n",
    "        Args:\n",
    "            pubmed_query (str): The search query for PubMed articles\n",
    "            page_size (int): Number of articles to fetch (default: 30)\n",
    "            \n",
    "        Returns:\n",
    "            list: A list of dictionaries containing article information\n",
    "        \"\"\"\n",
    "        url = \"https://www.ebi.ac.uk/europepmc/webservices/rest/search\"\n",
    "    \n",
    "        params = {\n",
    "            \"query\": pubmed_query + \" OPEN_ACCESS:Y\",\n",
    "            \"format\": \"json\",\n",
    "            \"pageSize\": page_size\n",
    "        }\n",
    "    \n",
    "        response = requests.get(url, params=params)\n",
    "        data = response.json()\n",
    "    \n",
    "        # Store all documents here\n",
    "        documents = []\n",
    "    \n",
    "        for res in data['resultList']['result']:\n",
    "            doc = {\n",
    "                \"title\": res.get('title'),\n",
    "                \"year\": res.get('pubYear'),\n",
    "                \"pmid\": res.get('pmcid', None),\n",
    "                \"abstract\": None,\n",
    "                \"conclusion\": None\n",
    "            }\n",
    "            \n",
    "            pmcid = res.get('pmcid')\n",
    "            if pmcid:\n",
    "                fulltext_url = f\"https://www.ebi.ac.uk/europepmc/webservices/rest/{pmcid}/fullTextXML\"\n",
    "                fulltext_response = requests.get(fulltext_url)\n",
    "                \n",
    "                if fulltext_response.status_code == 200:\n",
    "                    soup = BeautifulSoup(fulltext_response.content, 'xml')\n",
    "                    \n",
    "                    # Extract Abstract\n",
    "                    abstract = soup.find('abstract')\n",
    "                    if abstract:\n",
    "                        doc['abstract'] = abstract.get_text(separator=' ', strip=True)\n",
    "                    \n",
    "                    # Extract Results and Conclusion\n",
    "                    sections = soup.find_all('sec')\n",
    "                    for sec in sections:\n",
    "                        title_tag = sec.find('title')\n",
    "                        if title_tag:\n",
    "                            title_text = title_tag.get_text(strip=True).lower()\n",
    "                           \n",
    "                            if 'conclusion' in title_text and not doc['conclusion']:\n",
    "                                doc['conclusion'] = sec.get_text(separator=' ', strip=True)\n",
    "            \n",
    "            documents.append(doc)\n",
    "        \n",
    "        return documents\n",
    "    \n",
    "    e_pmc_docs = fetch_pubmed_articles(pubmed_query, page_size=n_docs)\n",
    "    #relevant documents from Europe PMC retrieved\n",
    "    print(len(e_pmc_docs))\n",
    "\n",
    "    df1 = pd.DataFrame(pub_docs)\n",
    "    df2 = pd.DataFrame(e_pmc_docs)\n",
    "    if 'df1' in locals() and not df1.empty:\n",
    "        df1['text'] = df1['abstract']\n",
    "    \n",
    "    \n",
    "    \n",
    "    if 'df2' in locals() and not df2.empty:\n",
    "        \n",
    "        # Safely handle missing abstract or conclusion\n",
    "        df2['text'] = df2['abstract'].fillna('').astype(str) + ' ' + df2['conclusion'].fillna('').astype(str) \n",
    "\n",
    "    #adding abstract and conclusion for RAG. rest all sections are ignored.\n",
    "    df = pd.concat([df1, df2], ignore_index=True)\n",
    "    if len(df)==0:\n",
    "        print('zero docs found')\n",
    "        return 'No docs found',None,None,None,None,None,None,None,None,None\n",
    "        # if no documents are retrieved for evaluation, then there is no evaluation. so, returns None.\n",
    "    df = df.apply(lambda col: col.map(lambda x: x.strip() if isinstance(x, str) else x))\n",
    "\n",
    "    #df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    df.replace('', np.nan, inplace=True)\n",
    "    \n",
    "    df = df.drop(['conclusion','abstract'\t], axis=1)\n",
    "    df=df.dropna()\n",
    "\n",
    "    if len(df)==0:\n",
    "        print('zero docs found')\n",
    "        return 'No docs found',None,None,None,None,None,None,None,None,None\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    def normalize_scores(scores):\n",
    "        # a function to normalize a sequence of numbers(metric scores)\n",
    "        min_score = min(scores)\n",
    "        max_score = max(scores)\n",
    "        if max_score == min_score:\n",
    "            return [1.0 for _ in scores]  # all same scores\n",
    "        return [(s - min_score) / (max_score - min_score) for s in scores]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Set your API key\n",
    "    openai.api_key = key\n",
    "    \n",
    "    # Your medical documents\n",
    "    texts = df['text'].tolist()\n",
    "    full_docs = [Document(page_content=txt) for txt in texts]\n",
    "    \n",
    "    titles= df['title'].tolist()\n",
    "    title_docs= [Document(page_content=title) for title in titles]\n",
    "    # 1. BM25 scoring\n",
    "    \n",
    "    def bm25(query,docs):\n",
    "        \"\"\"\n",
    "        The function calculates BM25 scores of any query and related texts(docs)  \n",
    "\n",
    "           Args:\n",
    "               query: any query or pubmed query\n",
    "               docs: The retrieved documents from pubmed and europe pmc combined.\n",
    "\n",
    "           Return:\n",
    "               returns normalized BM25 scores of query and docs\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        tokenized_corpus = [doc.page_content.split() for doc in docs]\n",
    "        bm25 = BM25Okapi(tokenized_corpus)\n",
    "        bm25_scores = bm25.get_scores(query)\n",
    "        return normalize_scores(bm25_scores)\n",
    "        \n",
    "    \n",
    "    \n",
    "    # 2. Dense vector scoring with OpenAI embeddings\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        model=\"text-embedding-3-large\",\n",
    "        openai_api_key=key)\n",
    "    \n",
    "    from numpy.linalg import norm\n",
    "    #calculates cosine similarity between a and b\n",
    "    def cosine_similarity(a, b):\n",
    "        return np.dot(a, b) / (norm(a) * norm(b))\n",
    "    \n",
    "    \n",
    "    def dense(query,docs):\n",
    "\n",
    "        \"\"\"\n",
    "        Calculate dense scores( cosine similarity between query and docs)\n",
    " \n",
    "            Args:\n",
    "               query: any query or pubmed query\n",
    "               docs: The retrieved documents from pubmed and europe pmc combined.\n",
    "\n",
    "            Returns:\n",
    "                    returns dense score\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "        query_embedding = embeddings.embed_query(query)\n",
    "        doc_embeddings = [embeddings.embed_query(doc.page_content) for doc in docs]\n",
    "        dense_scores = [cosine_similarity(query_embedding, emb) for emb in doc_embeddings]\n",
    "        return normalize_scores(dense_scores)\n",
    "    \n",
    "    bm25_query_docs = bm25(query.split(),full_docs)\n",
    "    # Extract all quoted phrases\n",
    "    pquery_keywords = re.findall(r'\"(.*?)\"', pubmed_query)\n",
    "    bm25_pubmed_query_docs=bm25(pquery_keywords,full_docs)\n",
    "    bm25_title_docs = bm25(query.split(),title_docs)\n",
    "    bm25_pubmed_query_title_docs=bm25(pquery_keywords,title_docs)\n",
    "    \n",
    "    dense_query_docs = dense(query,full_docs)\n",
    "    dense_pquery_docs = dense(\" \".join(pquery_keywords),full_docs)\n",
    "    dense_title_docs = dense(query,title_docs)\n",
    "    dense_pquery_title_docs = dense(\" \".join(pquery_keywords),title_docs)\n",
    "    dense_llmresponse_docs=dense(llmresponse,full_docs)\n",
    "\n",
    "\n",
    "    df['bm25_query_docs']=bm25_query_docs\n",
    "    df['bm25_pubmed_query_docs']=bm25_pubmed_query_docs\n",
    "    df['bm25_title_docs']=bm25_title_docs\n",
    "    df['bm25_pubmed_query_title_docs']=bm25_pubmed_query_title_docs\n",
    "    df['dense_query_docs']=dense_query_docs\n",
    "    df['dense_pquery_docs']=dense_pquery_docs\n",
    "    df['dense_title_docs']=dense_title_docs \n",
    "    df['dense_pquery_title_docs']=dense_pquery_title_docs\n",
    "    df['dense_llmresponse_docs']=dense_llmresponse_docs\n",
    "\n",
    "    df['score'] = (\n",
    "        0.20 * df[\"bm25_query_docs\"] +\n",
    "        0.10 * df[\"bm25_pubmed_query_docs\"] +\n",
    "        0.05 * df[\"bm25_title_docs\"] +\n",
    "        0.05 * df[\"bm25_pubmed_query_title_docs\"] +\n",
    "        0.25 * df[\"dense_query_docs\"] +\n",
    "        0.10 * df[\"dense_pquery_docs\"] +\n",
    "        0.05 * df[\"dense_title_docs\"] +\n",
    "        0.05 * df[\"dense_pquery_title_docs\"] +\n",
    "        0.10 * df[\"dense_llmresponse_docs\"] +\n",
    "        0.05 * df[\"year\"].apply(lambda y: max(0, 1 - (2025 - int(y)) / 10))\n",
    "    )\n",
    "    \n",
    "    if len(df)< 8:\n",
    "        top_k=df\n",
    "    else:\n",
    "        top_k = df.nlargest(k, 'score')\n",
    "    \n",
    "    def format_documents_for_gold_doc(df):\n",
    "        \"\"\"\n",
    "        Converts a DataFrame with pmid, title, and text columns into\n",
    "        a list of formatted document strings for LLM input.\n",
    "        \"\"\"\n",
    "        docs = []\n",
    "        for i, row in enumerate(df.itertuples(index=False), start=1):\n",
    "            doc_str = f\"\"\"Document {i} (PMID: {row.pmid})\n",
    "    Title: {row.title.strip()}\n",
    "    Text: {row.text.strip()}\"\"\"\n",
    "            docs.append(doc_str)\n",
    "        return docs\n",
    "    docs_4r_gold=format_documents_for_gold_doc(top_k)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def generate_pseudo_gold_document(query: str, documents: List[str], api_key: str, model: str = \"gpt-4-turbo\") -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Generates a pseudo-gold document by synthesizing information from multiple documents.\n",
    "        \n",
    "        Args:\n",
    "            query: The research question to address.\n",
    "            documents: List of document texts to use as sources.\n",
    "            api_key: OpenAI API key.\n",
    "            model: Which OpenAI model to use (defaults to \"gpt-4\").\n",
    "        \n",
    "        Returns:\n",
    "            The generated pseudo-gold document, or None if generation failed.\n",
    "        \"\"\"\n",
    "        # Validate inputs\n",
    "        if not query or not isinstance(query, str):\n",
    "            raise ValueError(\"Query must be a non-empty string\")\n",
    "        if not documents or not all(isinstance(doc, str) for doc in documents):\n",
    "            raise ValueError(\"Documents must be a non-empty list of strings\")\n",
    "        if not api_key or not isinstance(api_key, str):\n",
    "            raise ValueError(\"API key must be a non-empty string\")\n",
    "    \n",
    "        try:\n",
    "            # Format documents for context\n",
    "            context = \"\\n\\n\".join([f\"Document {i+1}:\\n{doc.strip()}\" \n",
    "                                 for i, doc in enumerate(documents) if doc.strip()])\n",
    "    \n",
    "            prompt = f\"\"\"You are a factual and meticulous research assistant.\n",
    "    \n",
    "    You are given a set of small research documents (abstracts and conclusions) and a query. Follow these steps carefully to create a pseudo-gold document that is fully grounded in the provided texts:\n",
    "    \n",
    "    Query: {query}\n",
    "    \n",
    "    Documents:\n",
    "    {context}\n",
    "    \n",
    "    Step-by-step instructions:\n",
    "    1. Extract and list the key facts or conclusions from each document. Tag them with the document number.\n",
    "    2. Identify any facts that are repeated or consistent across multiple documents.\n",
    "    3. Highlight any contradictions or disagreements between documents.\n",
    "    4. Reason about which facts are most reliable or most widely supported.\n",
    "    5. Write a concise, factually accurate summary that addresses the query, grounded only in the information from the documents. Use inline citations (e.g., [Doc 1], [Doc 3]) to show the source of each claim.\n",
    "    6. Insert the pmid after the document number \n",
    "    Only use information explicitly found in the documents. Do not invent, assume, or hallucinate any facts.\n",
    "    Include nothing else in your response except the requested summary.\"\"\"\n",
    "    \n",
    "            # Initialize client with API key\n",
    "            client = openai.OpenAI(api_key=api_key)\n",
    "            \n",
    "            # Call OpenAI API\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.1,\n",
    "                max_tokens=2800\n",
    "            )\n",
    "    \n",
    "            return response.choices[0].message.content\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating pseudo-gold document: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "\n",
    "    api_key = key \n",
    "        \n",
    "    pseudo_gold = generate_pseudo_gold_document(query, docs_4r_gold, api_key)\n",
    "    #pseudo gold docuent is generated\n",
    "\n",
    "    \n",
    "    dense_gold_doc_docs = dense(pseudo_gold ,full_docs)\n",
    "    df['gold']=dense_gold_doc_docs\n",
    "    df['final scores']=.75*df['score']+.25*df['gold']\n",
    "    \n",
    "    if len(df)< 8:\n",
    "        final_topk=df\n",
    "    else:\n",
    "        final_topk = df.nlargest(k, 'final scores')\n",
    "\n",
    "\n",
    "    def empathy_evaluation(question, response1, response2, response3,key):\n",
    "        \"\"\"\n",
    "        Evaluates and gives empathy ratings for responses and question.\n",
    "\n",
    "        Args:\n",
    "            question(str): query given by the user\n",
    "            response1(str): ChatGPT response \n",
    "            response2(str): Claude response\n",
    "            response3(str): Deepseek response\n",
    "\n",
    "        Return:\n",
    "            returns a string of empathy evalation with scores and explanation\n",
    "\n",
    "        \"\"\"\"\n",
    "        \n",
    "        client = OpenAI(api_key=key)\n",
    "        prompt = f\"\"\"\n",
    "        You are an empathy evaluator. Rate responses on a scale from 1 (least empathetic) to 10 (most empathetic). Empathy requires:\n",
    "        1. Acknowledging emotions (\"That sounds hard\")\n",
    "        2. Validating concerns (\"Your fear makes sense\")\n",
    "        3. Offering support (\"Let's work through this together\")\n",
    "    \n",
    "        ---\n",
    "        **Examples (10-point scale):**\n",
    "        Q: I had surgery and now my arm is numb. I'm scared.\n",
    "        A1: \"Numbness happens. Wait it out.\" → 1/10 (Dismissive)\n",
    "        A2: \"Post-op numbness can occur. Monitor symptoms.\" → 3/10 (Clinical, no empathy)\n",
    "        A3: \"I understand your concern. Let's check if this is normal.\" → 6/10 (Validates but lacks emotional depth)\n",
    "        A4: \"That sounds terrifying. Surgery recovery can be overwhelming. Let's review your symptoms together.\" → 10/10 (Emotionally attuned + support)\n",
    "    \n",
    "        Q: I've been anxious about my health nonstop.\n",
    "        A1: \"Just relax.\" → 2/10 (Dismissive)\n",
    "        A2: \"Anxiety is common. Try deep breathing.\" → 4/10 (Mildly helpful but generic)\n",
    "        A3: \"I hear how distressing this is. Would talking about it help?\" → 8/10 (Strong validation + offer to help)\n",
    "        \n",
    "        Q: My chronic pain is worse today.\n",
    "        A1: \"Pain fluctuates.\" → 1/10 (Cold)\n",
    "        A2: \"Consider taking medication.\" → 3/10 (Solution without empathy)\n",
    "        A3: \"I'm sorry you're hurting. Let's adjust your management plan.\" → 7/10 (Compassionate + actionable)\n",
    "        A4: \"Chronic pain is exhausting. I'm here to help you find relief.\" → 9/10 (Emotionally resonant + supportive)\n",
    "    \n",
    "        ---\n",
    "        **Evaluate these responses to:**\n",
    "        Q: {question}\n",
    "        A1: {response1}\n",
    "        A2: {response2}\n",
    "        A3: {response3}\n",
    "    \n",
    "        Return your evaluation in JSON format with the following structure:\n",
    "        {{\n",
    "            \"ratings\": [\n",
    "                {{\"chatgpt response\": \"A1\", \"rating\": 0, \"explanation\": \"Brief reason\"}},\n",
    "                {{\"claude response\": \"A2\", \"rating\": 0, \"explanation\": \"Brief reason\"}},\n",
    "                {{\"deepseek response\": \"A3\", \"rating\": 0, \"explanation\": \"Brief reason\"}}\n",
    "            ],\n",
    "            \"summary\": \"Overall comparison of empathy levels\"\n",
    "        }}\n",
    "        \"\"\"\n",
    "    \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4-turbo\",  # or \"gpt-4-turbo\" if available\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a precise empathy evaluator. Always return valid JSON.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.1,\n",
    "                max_tokens=800\n",
    "            )\n",
    "            # Extract the content and parse as JSON\n",
    "            response_content = response.choices[0].message.content\n",
    "            return json.loads(response_content)\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def evaluate_llm_response_with_docs(\n",
    "        query: str,\n",
    "        llm_response: str,\n",
    "        retrieved_docs: List[str],\n",
    "        api_key: str,\n",
    "        model: str = \"gpt-4o\"\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Evaluates the LLM response against retrieved documents using GPT-4o for medical QA quality.\n",
    "    \n",
    "        Args:\n",
    "            query: The original patient query.\n",
    "            llm_response: The response generated by the medical assistant.\n",
    "            retrieved_docs: A list of top relevant document texts used for retrieval.\n",
    "            api_key: Your OpenAI API key.\n",
    "            model: The GPT model to use (default: \"gpt-4o\").\n",
    "        \n",
    "        Returns:\n",
    "            Evaluation result from GPT-4o.\n",
    "        \"\"\"\n",
    "        # Join documents with indexing for citation and grounding\n",
    "        context = \"\\n\\n\".join([f\"Document {i+1}:\\n{doc.strip()}\" for i, doc in enumerate(retrieved_docs)])\n",
    "    \n",
    "        # Construct the evaluation prompt\n",
    "        eval_prompt = f\"\"\"\n",
    "    You are an expert medical QA evaluator. Your task is to assess the quality of an LLM-generated answer to a patient's medical query, using the retrieved research documents provided.\n",
    "    \n",
    "    Please evaluate the LLM response on the following criteria:\n",
    "    \n",
    "    1. **Correctness**: Are the statements medically accurate based on the retrieved documents?\n",
    "    2. **Hallucination**: Does the answer contain any unsupported or fabricated facts?\n",
    "    3. **Completeness**: Does it fully address the patient's question?\n",
    "    4. **Faithfulness**: Is the response faithful to the information in the documents?\n",
    "    5. **Groundedness**: Are claims supported with evidence from the documents?\n",
    "    6. **Details**: Give the PMIDs of documents and published year if available\n",
    "    7. **Values**: Provide all five scores as a list [correctness, hallucination, completeness, faithfulness, groundedness]\n",
    "    \n",
    "    Respond with a structured evaluation including scores (1-10) and explanations for each criterion.\n",
    "    \n",
    "    ---\n",
    "    **Patient Query**:  \n",
    "    {query}\n",
    "    \n",
    "    **LLM Response**:  \n",
    "    {llm_response}\n",
    "    \n",
    "    **Retrieved Documents**:  \n",
    "    {context}\n",
    "    \"\"\"\n",
    "    \n",
    "        try:\n",
    "            client = OpenAI(api_key=api_key)  # Correct initialization\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a clinical QA evaluation expert.\"},\n",
    "                    {\"role\": \"user\", \"content\": eval_prompt}\n",
    "                ],\n",
    "                temperature=0.2,\n",
    "                max_tokens=2000\n",
    "            )\n",
    "            return response.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Evaluation error: {e}\")\n",
    "            return \"Error during evaluation.\"\n",
    "    retrieved_docs = (final_topk['pmid']+ '  ' +final_topk['year']+ '  ' +final_topk['text']).to_list()\n",
    "    \n",
    "    chatgpt_RE = evaluate_llm_response_with_docs(\n",
    "    query=query,\n",
    "    llm_response=chatgpt_response,\n",
    "    retrieved_docs=retrieved_docs,\n",
    "    api_key=key ) # Replace with your actual API key\n",
    "\n",
    "    claude_RE = evaluate_llm_response_with_docs(\n",
    "    query=query,\n",
    "    llm_response=claude_response,\n",
    "    retrieved_docs=retrieved_docs,\n",
    "    api_key=key ) # Replace with your actual API key\n",
    "\n",
    "    deepseek_RE = evaluate_llm_response_with_docs(\n",
    "    query=query,\n",
    "    llm_response=deepseek_response,\n",
    "    retrieved_docs=retrieved_docs,\n",
    "    api_key=key )\n",
    "\n",
    "\n",
    "    empathy_evaluation= empathy_evaluation(query, chatgpt_response, claude_response, deepseek_response,key)\n",
    "\n",
    "    return pubmed_query,pseudo_gold,df,chatgpt_RE,claude_RE,deepseek_RE,empathy_evaluation,chatgpt_response, claude_response, deepseek_response\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fc9448-25d6-427e-bce6-a7d27c737013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5862a980-40e3-4690-8fc2-358c572d92f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47493</td>\n",
       "      <td>If you are a doctor, please answer the medical...</td>\n",
       "      <td>I wake in the night, usually about 2-3 hours a...</td>\n",
       "      <td>Dear patient Here are the possibilities of wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65740</td>\n",
       "      <td>If you are a doctor, please answer the medical...</td>\n",
       "      <td>Honorable Sir,I am Ripon Dev from Bangladesh.M...</td>\n",
       "      <td>Hi, Thanks for writing in. Please add detailed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69490</td>\n",
       "      <td>If you are a doctor, please answer the medical...</td>\n",
       "      <td>Ive had a cold which started on Christmas eve ...</td>\n",
       "      <td>Hi, Welcome to Chat Doctor! Yes, from what you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39656</td>\n",
       "      <td>If you are a doctor, please answer the medical...</td>\n",
       "      <td>I had cervical laminectomy surgery for spinal ...</td>\n",
       "      <td>Thanks for writing to us. You have complex sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45796</td>\n",
       "      <td>If you are a doctor, please answer the medical...</td>\n",
       "      <td>Hello, At the end of lacrosse practice about a...</td>\n",
       "      <td>Dear List, I believe you may have suffered a m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        instruction  \\\n",
       "0       47493  If you are a doctor, please answer the medical...   \n",
       "1       65740  If you are a doctor, please answer the medical...   \n",
       "2       69490  If you are a doctor, please answer the medical...   \n",
       "3       39656  If you are a doctor, please answer the medical...   \n",
       "4       45796  If you are a doctor, please answer the medical...   \n",
       "\n",
       "                                               input  \\\n",
       "0  I wake in the night, usually about 2-3 hours a...   \n",
       "1  Honorable Sir,I am Ripon Dev from Bangladesh.M...   \n",
       "2  Ive had a cold which started on Christmas eve ...   \n",
       "3  I had cervical laminectomy surgery for spinal ...   \n",
       "4  Hello, At the end of lacrosse practice about a...   \n",
       "\n",
       "                                              output  \n",
       "0  Dear patient Here are the possibilities of wha...  \n",
       "1  Hi, Thanks for writing in. Please add detailed...  \n",
       "2  Hi, Welcome to Chat Doctor! Yes, from what you...  \n",
       "3  Thanks for writing to us. You have complex sto...  \n",
       "4  Dear List, I believe you may have suffered a m...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sample_queries=pd.read_csv(r\"C:\\Users\\shrav\\Downloads\\sample_responses.csv\")\n",
    "sample_queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cd1d488e-1227-42b3-8549-39b14a38367d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "zero docs found\n",
      "1\n",
      "64\n",
      "64\n",
      "2\n",
      "1\n",
      "64\n",
      "3\n",
      "1\n",
      "64\n",
      "4\n",
      "64\n",
      "64\n",
      "5\n",
      "0\n",
      "0\n",
      "zero docs found\n",
      "6\n",
      "0\n",
      "2\n",
      "zero docs found\n",
      "7\n",
      "5\n",
      "64\n",
      "8\n",
      "22\n",
      "64\n",
      "9\n",
      "1\n",
      "64\n",
      "10\n",
      "41\n",
      "64\n",
      "11\n",
      "0\n",
      "45\n",
      "12\n",
      "0\n",
      "30\n",
      "13\n",
      "0\n",
      "6\n",
      "14\n",
      "0\n",
      "64\n",
      "15\n",
      "0\n",
      "3\n",
      "16\n",
      "22\n",
      "64\n",
      "17\n",
      "0\n",
      "2\n",
      "zero docs found\n",
      "18\n",
      "64\n",
      "64\n",
      "19\n",
      "30\n",
      "64\n",
      "20\n",
      "5\n",
      "41\n",
      "21\n",
      "10\n",
      "64\n",
      "22\n",
      "25\n",
      "64\n",
      "23\n",
      "64\n",
      "64\n",
      "24\n",
      "13\n",
      "64\n",
      "25\n",
      "4\n",
      "64\n",
      "26\n",
      "0\n",
      "64\n",
      "27\n",
      "0\n",
      "12\n",
      "28\n",
      "63\n",
      "64\n",
      "29\n",
      "7\n",
      "13\n",
      "30\n",
      "2\n",
      "64\n",
      "31\n",
      "0\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "data=pd.DataFrame()    #dataframe that has all BM25, dense and final scores\n",
    "pubmed_queries=[]      #list that has all LLM generated pubmed queries\n",
    "pseudo_gold_docs=[]    #list that has all LLM generated golden documents\n",
    "chatgpt_REs=[]         #list that has all evaluation results for chatgpt responses\n",
    "claude_REs=[]          #list that has all evalation results for claude responses\n",
    "deepseek_REs=[]        #list that has all evalation results for deepseek responses\n",
    "chatgpt_responses=[]   #list that has all responses generated by chatgpt for user medical queries\n",
    "claude_responses=[]    #list that has all responses generated by claude for user medical queries\n",
    "deepseek_responses=[]  #list that has all responses generated by deepseek for user medical queries\n",
    "emapthy_evaluations=[] #list that has all empathy evaluation results\n",
    "for query in sample_queries['input']:\n",
    "    print(i)\n",
    "    n_docs=64\n",
    "    key= 'YOUR OPENAI KEY'\n",
    "    claude_key= \"YOUR CLAUDE KEY\"\n",
    "    deepseek_key=\"YOUR DEEPSEEK KEY\"\n",
    "    \n",
    "    k=10\n",
    "    pubmed_query,pseudo_gold,temp_df,chatgpt_RE,claude_RE,deepseek_RE,empathy_evaluation,chatgpt_response, claude_response, deepseek_response=ARES(n_docs, query, key ,k, claude_key,deepseek_key )\n",
    "    \n",
    "    if temp_df is not None and not temp_df.empty:\n",
    "        \n",
    "        temp_df['query_id'] = i\n",
    "        data = pd.concat([data, temp_df], ignore_index=True)\n",
    "\n",
    "    pubmed_queries.append(pubmed_query)\n",
    "    pseudo_gold_docs.append(pseudo_gold)\n",
    "    chatgpt_REs.append(chatgpt_RE)\n",
    "    claude_REs.append(claude_RE)\n",
    "    deepseek_REs.append(deepseek_RE)\n",
    "    chatgpt_responses.append(chatgpt_response)\n",
    "    claude_responses.append(claude_response) \n",
    "    deepseek_responses.append(deepseek_response)\n",
    "    emapthy_evaluations.append(empathy_evaluation)\n",
    "    i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5c2dc633-ac27-453a-b836-e78f0eb00e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#dataframe to store all results from ARES\n",
    "dfr = pd.DataFrame({\n",
    "    \"pubmed_query\": pubmed_queries,\n",
    "    \"pseudo_gold\": pseudo_gold_docs,\n",
    "    \"chatgpt_RE\": chatgpt_REs,\n",
    "    \"claude_RE\": claude_REs,\n",
    "    \"deepseek_RE\": deepseek_REs,\n",
    "    \"empathy evaluations\":emapthy_evaluations,\n",
    "    \"chatgpt responses\":chatgpt_responses,\n",
    "    \"claude responses\":claude_responses,\n",
    "    \"deepseek responses\":deepseek_responses\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "779e11b2-377e-4a45-bf32-3c89734359d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "dfr.to_csv(\"capstone_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1d31e5-5b30-49c8-8866-aaaa4e5c6469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
